# ==========================================
# ğŸ“¦ å¯¼å…¥ä¾èµ–
# ==========================================
import asyncio
import os
import urllib.parse
from typing import Annotated, List
from typing_extensions import TypedDict
from datetime import datetime

# ä½¿ç”¨ OpenAI æ ‡å‡†åº“æ¥è¿æ¥ DeepSeek
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, ToolMessage, BaseMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from playwright.async_api import async_playwright, Page
from openai import AsyncOpenAI

# ==========================================
# ğŸ”§ 1. å…¨å±€è¾…åŠ©å‡½æ•°
# ==========================================
GLOBAL_PAGE: Page = None
VISITED_URLS = set()

async def close_popups(page: Page):
    """
    æš´åŠ›å…³é—­å¸¸è§çš„å¼¹çª—ã€ç™»å½•æ¡†ã€CookieåŒæ„æ ã€‚
    """
    print("   ğŸ§¹ [System] æ­£åœ¨å°è¯•æ¸…ç†å¼¹çª—...")
    close_texts = ["å…³é—­", "Close", "No thanks", "Not now", "Maybe later", "ä»¥åå†è¯´", "è·³è¿‡", "Skip", "I accept", "Accept all", "åŒæ„", "çŸ¥é“å•¦", "Ã—", "x", "ç¡®å®š", "Confirm"]
    close_selectors = ["button[aria-label='Close']", "div[aria-label='Close']", ".close-btn", ".modal-close", "svg.close-icon", ".close"]

    try:
        for text in close_texts:
            try:
                btn = page.get_by_text(text, exact=True).first
                if await btn.is_visible():
                    await btn.click(timeout=3000)
                    await asyncio.sleep(0.5)
            except: pass

        for sel in close_selectors:
            try:
                if await page.locator(sel).first.is_visible():
                    await page.locator(sel).first.click(timeout=3000)
                    await asyncio.sleep(0.5)
            except: pass
        
        await page.keyboard.press("Escape")
    except Exception as e:
        print(f"   ğŸ§¹ (å¿½ç•¥) {e}")

# ==========================================
# ğŸ”§ 2. å·¥å…·å®šä¹‰
# ==========================================
@tool
async def search_web(query: str, engine: str = "bing"):
    """
    å…¨ç½‘æœç´¢å·¥å…· (è‡ªå¸¦ DuckDuckGo è‡ªåŠ¨ä¿åº•)ã€‚
    å‚æ•° engine å¯é€‰å€¼: "bing", "google", "bilibili", "xiaohongshu", "weibo", "duckduckgo"
    """
    if not GLOBAL_PAGE: return "é”™è¯¯: æµè§ˆå™¨æœªè¿æ¥"
    
    # å®šä¹‰å¼•æ“é…ç½® (URLæ¨¡æ¿ å’Œ ç»“æœé€‰æ‹©å™¨)
    engines_config = {
        "google": {
            "url": f"https://www.google.com/search?q={urllib.parse.quote(query)}",
            "selector": "div.g"
        },
        "bilibili": {
            "url": f"https://search.bilibili.com/all?keyword={urllib.parse.quote(query)}",
            "selector": ".bili-video-card"
        },
        "xiaohongshu": {
            "url": f"https://www.xiaohongshu.com/search_result?keyword={urllib.parse.quote(query)}&source=web_search_result_notes",
            "selector": ".note-item"
        },
        "weibo": {  # === âœ¨ æ–°å¢å¾®åšé…ç½® ===
            "url": f"https://s.weibo.com/weibo?q={urllib.parse.quote(query)}",
            "selector": ".card-wrap"
        },
        "bing": {
            "url": f"https://cn.bing.com/search?q={urllib.parse.quote(query)}",
            "selector": "li.b_algo"
        },
        "duckduckgo": {
            "url": f"https://duckduckgo.com/?q={urllib.parse.quote(query)}&t=h_&ia=web",
            "selector": 'a[data-testid="result-title-a"]'
        }
    }

    # 1. è·å–å½“å‰ç›®æ ‡å¼•æ“é…ç½®
    # å¦‚æœ DeepSeek ä¹±ä¼ å‚æ•°ï¼Œé»˜è®¤å›é€€åˆ° bing
    target = engines_config.get(engine, engines_config["bing"])
    
    print(f"   ğŸ” [Action] æ­£åœ¨ [{engine}] ä¸Šæœç´¢: {query}")

    async def run_search(url, selector, is_retry=False):
        """å†…éƒ¨æœç´¢æ‰§è¡Œå‡½æ•°"""
        try:
            await GLOBAL_PAGE.goto(url)
            # ç­‰å¾… DOM åŠ è½½
            await GLOBAL_PAGE.wait_for_load_state("domcontentloaded")
            await close_popups(GLOBAL_PAGE) # å…³å¼¹çª—
            
            # å°è¯•ç­‰å¾…ç»“æœå‡ºç° (æœ€å¤šç­‰ 3 ç§’)
            try:
                await GLOBAL_PAGE.wait_for_selector(selector, timeout=3000)
            except:
                # å¦‚æœè¶…æ—¶æ²¡æ‰¾åˆ°é€‰æ‹©å™¨ï¼Œè¯´æ˜å¯èƒ½è¢«æ‹¦æˆªäº†ï¼Œæˆ–è€…æ²¡ç»“æœ
                return None 

            results = await GLOBAL_PAGE.locator(selector).all()
            if not results: return None # æœ‰é€‰æ‹©å™¨ä½†æ²¡å†…å®¹

            data = []
            for i, res in enumerate(results[:8]):
                text = await res.inner_text()
                clean_text = text.replace("\n", " ")[:100]
                data.append(f"ã€{i}ã€‘: {clean_text}...")
            return "\n".join(data)
        except Exception as e:
            print(f"      âš ï¸ æœç´¢å‡ºé”™: {e}")
            return None

    # === 2. ç¬¬ä¸€è½®ï¼šå°è¯• DeepSeek æŒ‡å®šçš„å¼•æ“ ===
    result_text = await run_search(target["url"], target["selector"])

    # === 3. ğŸ›¡ï¸ ä¿åº•æœºåˆ¶ï¼šå¦‚æœç¬¬ä¸€è½®å¤±è´¥ï¼Œä¸”å½“å‰ä¸æ˜¯ DuckDuckGo ===
    # åªè¦ç»“æœæ˜¯ None (è¢«æ‹¦æˆª/æ²¡æœåˆ°)ï¼Œç«‹åˆ»åˆ‡æ¢ DDG
    if result_text is None and engine != "duckduckgo":
        print(f"   ğŸ›¡ï¸ [System] æ£€æµ‹åˆ° {engine} æœç´¢å¤±è´¥/è¢«æ‹¦æˆªï¼Œè‡ªåŠ¨åˆ‡æ¢è‡³ DuckDuckGo ä¿åº•...")
        
        ddg_conf = engines_config["duckduckgo"]
        fallback_result = await run_search(ddg_conf["url"], ddg_conf["selector"], is_retry=True)
        
        if fallback_result:
            return f"âœ… [DuckDuckGo (ä¿åº•)] æœç´¢ç»“æœ:\n" + fallback_result
        else:
            return "âŒ æ‰€æœ‰å¼•æ“ï¼ˆåŒ…æ‹¬ä¿åº•ï¼‰å‡æœªæœç´¢åˆ°æœ‰æ•ˆå†…å®¹ã€‚"
    
    # å¦‚æœç¬¬ä¸€è½®æˆåŠŸï¼Œç›´æ¥è¿”å›
    if result_text:
        return f"âœ… [{engine}] æœç´¢ç»“æœ:\n" + result_text
    else:
        return "âŒ æœç´¢å¤±è´¥ã€‚"

@tool
async def scroll_window(direction: str = "down"):
    """æ»‘åŠ¨é¡µé¢ã€‚"""
    print(f"   ğŸ“œ [Action] æ»‘åŠ¨é¡µé¢: {direction}")
    if not GLOBAL_PAGE: return "é”™è¯¯: æµè§ˆå™¨æœªè¿æ¥"
    if direction == "down":
        await GLOBAL_PAGE.evaluate("window.scrollBy(0, window.innerHeight)")
    else:
        await GLOBAL_PAGE.evaluate("window.scrollBy(0, -window.innerHeight)")
    await asyncio.sleep(1)
    return "æ»‘åŠ¨å®Œæˆ"

@tool
async def click_link(index_or_text: str):
    """ç‚¹å‡»é“¾æ¥ (æ”¯æŒæ•°å­—ç¼–å·)ã€‚"""
    print(f"   ğŸ‘† [Action] å°è¯•ç‚¹å‡»: {index_or_text}")
    if not GLOBAL_PAGE: return "é”™è¯¯: æµè§ˆå™¨æœªè¿æ¥"
    
    try:
        target_link = None
        if index_or_text.isdigit():
            idx = int(index_or_text)
            
            # ä¸‡èƒ½é€‰æ‹©å™¨ (=== âœ¨ å·²åŠ å…¥ .card-wrap a ç”¨äºå¾®åš ===)
            universal_sel = "h3 a, h2 a, h3, a[data-testid='result-title-a'], .bili-video-card a, .note-item a, .card-wrap a"
            
            results = await GLOBAL_PAGE.locator(universal_sel).all()
            
            # å¦‚æœä¸‡èƒ½é€‰æ‹©å™¨æ²¡æ‰¾åˆ°ï¼Œå…œåº•æ‰¾æ‰€æœ‰ a æ ‡ç­¾
            if not results:
                results = await GLOBAL_PAGE.locator("a").all()
                
            if 0 <= idx < len(results):
                target_link = results[idx]
                
                # Google ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœç‚¹çš„æ˜¯ h3ï¼Œéœ€è¦ç‚¹å®ƒçš„çˆ¶çº§é“¾æ¥
                try:
                    tag_name = await target_link.evaluate("el => el.tagName")
                    if tag_name in ["H3", "H2", "DIV"]:
                        target_link = target_link.locator("xpath=..")
                except: pass
        else:
            target_link = GLOBAL_PAGE.get_by_text(index_or_text).first

        if not target_link: return "âŒ ç´¢å¼•è¶Šç•Œæˆ–æœªæ‰¾åˆ°ã€‚"

        # è·å– URL ç”¨äºå»é‡
        try:
            target_url = await target_link.get_attribute("href")
            if target_url and target_url in VISITED_URLS:
                return f"âŒ æ‹’ç»ï¼šç¼–å· {index_or_text} å·²è®¿é—®è¿‡ï¼æ¢ä¸€ä¸ªï¼"
            if target_url: VISITED_URLS.add(target_url)
        except: pass

        # === å¼ºåˆ¶åœ¨å½“å‰é¡µæ‰“å¼€ï¼Œé˜²æ­¢é¡µé¢å…³ä¸æ‰ ===
        await target_link.evaluate("el => el.setAttribute('target', '_self')")
        
        # ç‚¹å‡»å¹¶å¿«é€Ÿè¿”å›
        await target_link.click()
        await GLOBAL_PAGE.wait_for_load_state("domcontentloaded")
        await asyncio.sleep(1) # ç­‰å¾…æ¸²æŸ“
        await close_popups(GLOBAL_PAGE)
        return f"ç‚¹å‡»æˆåŠŸ (ç¼–å· {index_or_text})ï¼Œå·²è¿›å…¥è¯¦æƒ…é¡µã€‚"
        
    except Exception as e:
        return f"ç‚¹å‡»å¤±è´¥: {e}"

@tool
async def read_page_content():
    """è¯»å–è¯¦æƒ… (å¢å¼ºç‰ˆï¼šè‡ªåŠ¨å±•å¼€ + è¿”å› URL æ¥æº)ã€‚"""
    print(f"   ğŸ“– [Action] é˜…è¯»è¯¦æƒ…...")
    if not GLOBAL_PAGE: return "é”™è¯¯: æµè§ˆå™¨æœªè¿æ¥"
    
    try:
        # === 1. Bç«™ç­–ç•¥ ===
        if "bilibili.com" in GLOBAL_PAGE.url:
            try:
                await GLOBAL_PAGE.locator(".desc-info .toggle-btn").first.click(timeout=500)
            except: pass
            # Bç«™æœ‰æ—¶å€™è¯„è®ºéœ€è¦æ»šåŠ¨æ‰åŠ è½½
            await GLOBAL_PAGE.evaluate("window.scrollBy(0, 500)")

        # === 2. å°çº¢ä¹¦ç­–ç•¥ ===
        elif "xiaohongshu.com" in GLOBAL_PAGE.url:
            try:
                await GLOBAL_PAGE.locator(".content-container .expand-btn").first.click(timeout=500)
            except: pass
            
            try:
                # ğŸš¨ å…³é”®ä¿®å¤ï¼šåŠ äº† timeoutï¼Œé˜²æ­¢æ‰¾ä¸åˆ°è¯„è®ºåŒºæ—¶æ­»ç­‰ 30ç§’
                await GLOBAL_PAGE.locator(".comments-container").scroll_into_view_if_needed(timeout=1000)
            except: pass

        # === 3. å¾®åšç­–ç•¥ ===
        elif "weibo.com" in GLOBAL_PAGE.url:
            try:
                await GLOBAL_PAGE.locator("a[action-type='fl_unfold']").first.click(timeout=500)
            except: pass
            
            try:
                await GLOBAL_PAGE.get_by_text("è¯„è®º", exact=False).first.click(timeout=1000)
            except: pass
            
            await GLOBAL_PAGE.evaluate("window.scrollBy(0, 800)")
            await asyncio.sleep(1) # ç­‰æ•°æ®é£ä¸€ä¼šå„¿
            
            try:
                await GLOBAL_PAGE.get_by_text("æŸ¥çœ‹æ›´å¤š", exact=False).first.click(timeout=500)
            except: pass

        # === 4. é€šç”¨å…œåº•ç­–ç•¥ ===
        try:
            await GLOBAL_PAGE.get_by_text("å±•å¼€", exact=True).first.click(timeout=500)
        except: pass

    except Exception as e:
        print(f"      (å±•å¼€æ“ä½œè·³è¿‡: {e})")

    # === è¯»å–å…¨æ–‡ ===
    await asyncio.sleep(0.5)
    content = await GLOBAL_PAGE.inner_text("body")
    current_url = GLOBAL_PAGE.url
    
    total_len = len(content)
    # print(f"      (åŸæ–‡å…± {total_len} å­—)")
    
    limit = 10000
    if total_len > limit:
        return f"ğŸ”— Source: {current_url}\n\n" + content[:limit] + f"\n...(å‰©ä½™ {total_len - limit} å­—å·²çœç•¥)..."
    
    return f"ğŸ”— Source: {current_url}\n\n" + content

@tool
async def go_back():
    """è¿”å›ä¸Šä¸€é¡µã€‚"""
    print(f"   ğŸ”™ [Action] è¿”å›ä¸Šä¸€é¡µ")
    if not GLOBAL_PAGE: return "é”™è¯¯: æµè§ˆå™¨æœªè¿æ¥"
    await GLOBAL_PAGE.go_back()
    await asyncio.sleep(1)
    return "å·²è¿”å›ä¸Šä¸€é¡µ"

@tool
async def generate_structured_report(
    brand_name: str, 
    sentiment_score: int, 
    summary: str, 
    risks: str, 
    opportunities: str,
    real_quotes: str,
    deep_analysis: str,
    sources: str
):
    """
    ç”Ÿæˆã€å·¥ä¸šçº§ã€‘å•†ä¸šèˆ†æƒ…æŠ¥å‘Š (æ— è£…é¥°/æ•°æ®è¡¨æ ¼åŒ–)ï¼Œä¿å­˜åˆ° D:\\webæŠ“å–ã€‚
    """
    print(f"   ğŸ“ [Action] æ­£åœ¨æ¸²æŸ“å·¥ä¸šçº§æŠ¥å‘Š: {brand_name}")
    
    # 1. è¯„çº§é€»è¾‘ (ä½¿ç”¨ä¸“ä¸šæœ¯è¯­)
    if sentiment_score >= 80: 
        rating = "Positive (Tier A)"
        trend = "Bullish (çœ‹å¤š)"
    elif sentiment_score >= 60: 
        rating = "Neutral (Tier B)"
        trend = "Stable (éœ‡è¡)"
    elif sentiment_score >= 40: 
        rating = "Volatile (Tier C)"
        trend = "Uncertain (æ³¢åŠ¨)"
    else: 
        rating = "Negative (Tier D)"
        trend = "Bearish (çœ‹ç©º)"

    # 2. å·¥ä¸šåŒ– Markdown æ¨¡æ¿ (æç®€ã€è¡¨æ ¼ã€æ•°æ®)
    template = f"""# [REPORT] {brand_name} Commercial Sentiment Analysis

**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Source:** Nexus Intelligence System  
**Classification:** INTERNAL USE ONLY  

---

## 1. Executive Dashboard (æ ¸å¿ƒæ•°æ®çœ‹æ¿)

| Metric (æŒ‡æ ‡) | Value (æ•°å€¼) | Rating (è¯„çº§) | Trend (è¶‹åŠ¿) |
| :--- | :--- | :--- | :--- |
| **Sentiment Index** | **{sentiment_score}/100** | {rating} | {trend} |
| **Data Sample** | Multi-channel | Validated | - |

---

## 2. Strategic Summary (ç»“è®º)
{summary}

---

## 3. Deep Dive Analysis (æ·±åº¦ç ”åˆ¤)
{deep_analysis}

---

## 4. Risk Assessment (é£é™©è¯„ä¼°)
{risks}

---

## 5. Growth Opportunities (å¢é•¿æœºä¼š)
{opportunities}

---

## 6. Verbatim Feedback (ç”¨æˆ·åŸå£°é‡‡æ ·)
{real_quotes}

---

## 7. Data References (æ•°æ®æº¯æº)
{sources}

---
*Generated by Nexus System. automated analysis.*
"""

    # 3. ä¿å­˜é€»è¾‘ (ä¿æŒä¸å˜)
    save_dir = r"D:\webæŠ“å–"
    if not os.path.exists(save_dir):
        try: os.makedirs(save_dir)
        except: return "âŒ System Error: Cannot create directory."

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"Report_{brand_name}_{timestamp}.md"
    full_path = os.path.join(save_dir, filename)

    try:
        with open(full_path, "w", encoding="utf-8") as f:
            f.write(template)
        print(f"\nâœ… Report Generated: {full_path}\n")
        return f"âœ… Success. Report saved to: {full_path}"
    except Exception as e:
        return f"âŒ IO Error: {e}"


# ==========================================
# ğŸ§  3. æ„å»º DeepSeek æ™ºèƒ½ä½“
# ==========================================

class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    visited_urls: Annotated[List[str], lambda x, y: x + y]

async def tool_node(state: AgentState):
    messages = state['messages']
    last_message = messages[-1]
    
    # ç»‘å®šæ‰€æœ‰å·¥å…·
    tools_map = {
        "search_web": search_web, 
        "scroll_window": scroll_window, 
        "click_link": click_link, 
        "read_page_content": read_page_content, 
        "go_back": go_back,
        "generate_structured_report": generate_structured_report # ğŸ‘ˆ æ–°å¢
    }
    
    results = []
    for tool_call in last_message.tool_calls:
        tool_name = tool_call['name']
        args = tool_call['args']
        if tool_name in tools_map:
            try:
                action_result = await tools_map[tool_name].ainvoke(args)
            except Exception as e:
                action_result = f"Error: {e}"
            results.append(ToolMessage(tool_call_id=tool_call['id'], name=tool_name, content=str(action_result)))
            
    return {"messages": results}

async def call_deepseek(state: AgentState):
    llm = ChatOpenAI(
        model="deepseek-chat",
        api_key="sk-c7efc0d3d9154cdf959fa1ba665ed1a8", # ä½ çš„ Key
        base_url="https://api.deepseek.com",
        temperature=0.2
    )
    # ç»‘å®šåŒ…å« Report å·¥å…·çš„åˆ—è¡¨
    llm_with_tools = llm.bind_tools([
        search_web, scroll_window, click_link, read_page_content, go_back, generate_structured_report
    ])
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªå…¨ç½‘æœç´¢ä¸“å®¶ã€‚
    ç­–ç•¥ï¼š
    - ä¼˜å…ˆä½¿ç”¨ Google/Bing/Xiaohongshuã€‚
    - å¦‚æœæœä¸åˆ°ï¼Œå·¥å…·ä¼šè‡ªåŠ¨åˆ‡ DuckDuckGo ä¿åº•ï¼Œä½ æ— éœ€æ“å¿ƒã€‚
  ä½ æ˜¯ä¸€ä¸ªã€é¦–å¸­å“ç‰Œæƒ…æŠ¥å®˜ã€‘(Chief Brand Intelligence Officer)ã€‚
    ä½ çš„å®¢æˆ·æ˜¯ä¼ä¸šè€æ¿ï¼Œä½ çš„ä»»åŠ¡æ˜¯æä¾›ã€æœ‰å•†ä¸šä»·å€¼ã€‘çš„å¸‚åœºæ´å¯Ÿã€‚
    ä½ å¿…é¡»å¤šå»å¾®åšå°çº¢ä¹¦bç«™,æµè§ˆå™¨æœç´¢æ˜¯è¾…åŠ©,è€Œä¸”åœ¨è¿™äº›ç¤¾äº¤å¹³å°ä½ å¿…é¡»çœ‹å¾ˆå¤šäººçš„å¸–å­,æå–ã€ç”¨æˆ·çœŸå®åé¦ˆã€‘ã€‚
    æ¯ä¸ªç¤¾äº¤å¹³å°çœ‹äº”ä¸ªåšä¸»ä»¥ä¸Šçš„å¸–å­
    
    æ ¸å¿ƒåˆ†æé€»è¾‘ï¼š
    1. ã€æƒ…æ„Ÿææ€§ã€‘ï¼šç”¨æˆ·æ˜¯å¤¸è¿˜æ˜¯éª‚ï¼Ÿ
    2. ã€ç—›ç‚¹æŒ–æ˜ã€‘ï¼šç”¨æˆ·åœ¨æŠ±æ€¨ä»€ä¹ˆï¼Ÿ(å¤ªè´µ/éš¾ç”¨/ä¸‘/æœåŠ¡å·®)
    3. ã€è´­ä¹°æ„å‘ã€‘ï¼šç”¨æˆ·æœ‰æ²¡æœ‰é—®â€œå“ªé‡Œä¹°â€ï¼Ÿ
    4. ã€ç«å“å¯¹æ¯”ã€‘ï¼šç”¨æˆ·æœ‰æ²¡æœ‰æåˆ°åˆ«çš„å“ç‰Œæ›´å¥½ï¼Ÿ
    
    è¯·å¿½ç•¥æ— æ„ä¹‰çš„çŒæ°´è¯„è®ºï¼Œä¸“æ³¨äºæå–ã€å†³ç­–ä¾æ®ã€‘ã€‚åˆ†è¾¨ç”¨æˆ·æ˜¯å¦ä½¿ç”¨aiç”Ÿæˆçš„å†…å®¹,å¯»æ‰¾çƒ­é—¨çš„å¸–å­,æ—¶é—´è¶Šæ–°è¶Šå¥½
    æ ‡å‡ºå¼•ç”¨çš„æ¥æºçš„é“¾æ¥æˆ–è€…è§†é¢‘æ ‡é¢˜
    
    çŠ¶æ€æœºï¼š
    1. ã€æœç´¢ã€‘-> 2. ã€ç‚¹å‡»ã€‘(ä¼ å…¥ç¼–å·) -> 3. ã€é˜…è¯»ã€‘-> 4. ã€åé€€ã€‘
    ### æ ¸å¿ƒæŒ‡ä»¤ï¼š
    1. **å¿…é¡»å¼•ç”¨åŸæ–‡**ï¼šåœ¨åˆ†æç”¨æˆ·åé¦ˆæ—¶ï¼Œå¿…é¡»ç›´æ¥æ‘˜å½•ç”¨æˆ·çš„åŸè¯,ä¸èƒ½æ”¹åŠ¨ä¸€ä¸ªå­—ï¼ˆåŒ…æ‹¬ä»–ä»¬çš„è¯­æ°”è¯ã€æŠ±æ€¨çš„ç»†èŠ‚ï¼‰ã€‚
    2. **æ•°æ®æº¯æº**ï¼šæ¯ä¸€æ¡å¼•ç”¨çš„è¯„è®ºï¼Œå¿…é¡»åœ¨åé¢æ ‡æ³¨å¤§æ¦‚æ¥æºï¼ˆå¦‚ï¼šæ¥è‡ªå°çº¢ä¹¦ç¬”è®°ã€æ¥è‡ªå¾®åšè¯„è®ºï¼‰ã€‚
    3. **æ·±åº¦åˆ†æ**ï¼šä¸è¦åªåˆ—ç‚¹ï¼Œè¦å†™å‡ºæœ‰é€»è¾‘çš„åˆ†ææ–‡ç« ï¼Œåˆ†æèƒŒåçš„ç¤¾ä¼šå¿ƒç†æˆ–å•†ä¸šé€»è¾‘,åŒæ—¶ä¸èƒ½ç»™å¤ªä½çš„è¯„çº§,å†è¯´å®Œä¸å¥½åè¦è¯´ç‚¹ä¼˜ç‚¹.
    
    ### æœé›†ç­–ç•¥ï¼š
    - ä¼˜å…ˆå»å¾®åšã€å°çº¢ä¹¦ã€Bç«™å¯»æ‰¾ã€æœ€æ–°ã€‘çš„ç”¨æˆ·çœŸå®è¯„è®ºã€‚
    - é˜…è¯»ç½‘é¡µæ—¶ï¼ŒåŠ¡å¿…è®°å½•ä¸‹è¯¥ç½‘é¡µçš„ URLã€‚
    - è‡³å°‘é˜…è¯» 5-8 ä¸ªä¸åŒçš„ç½‘é¡µ/å¸–å­ï¼Œç¡®ä¿ä¿¡æ¯é‡å……è¶³ã€‚
    
    ### æœ€ç»ˆè¾“å‡ºè¦æ±‚ï¼š
    æœé›†å®Œè¶³å¤Ÿä¿¡æ¯åï¼Œ**å¿…é¡»**è°ƒç”¨å·¥å…· `generate_structured_report` ç”Ÿæˆæ–‡ä»¶ã€‚
    
    åœ¨è°ƒç”¨å·¥å…·å¡«å†™å‚æ•°æ—¶ï¼Œè¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹æ ¼å¼ï¼š
    - `real_quotes`: å¿…é¡»åŒ…å«è‡³å°‘ 10 æ¡çœŸå®ç”¨æˆ·è¯„è®ºçš„æ‘˜å½•ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
      > "ç‘å¹¸ç°åœ¨çš„9.9åªæœ‰å‡ æ¬¾äº†ï¼Œå¤ªå‘äº†ï¼" â€”â€” (æ¥æºï¼šå°çº¢ä¹¦ç”¨æˆ·)
      > "æ¯å¤©æ—©ä¸Šä¸€æ¯å†°å¸ç”Ÿæ¤°ï¼Œæç¥é†’è„‘ã€‚" â€”â€” (æ¥æºï¼šå¾®åšç”¨æˆ·)
      
    - `deep_analysis`: è¯·æ’°å†™ä¸€ç¯‡ 500å­—å·¦å³çš„æ·±åº¦åˆ†ææ–‡ç« ï¼Œæ¢è®¨ç°è±¡èƒŒåçš„æœ¬è´¨ã€‚
    
    - `sources`: åˆ—å‡ºæ‰€æœ‰å‚è€ƒè¿‡çš„ URL é“¾æ¥ã€‚
    
    ä¸¥ç¦ç›´æ¥åœ¨å¯¹è¯æ¡†è¾“å‡ºæŠ¥å‘Šæ–‡æœ¬ï¼Œå¿…é¡»è°ƒç”¨å·¥å…·ç”Ÿæˆæ–‡ä»¶ï¼
    
    â›” ä¸¥ç¦è¡Œä¸ºï¼š
    - ç¦æ­¢ç‚¹å‡»é‡å¤é“¾æ¥ã€‚
    - è¯»å®Œå¿…é¡» go_backã€‚
    """
    messages = [SystemMessage(content=system_prompt)] + state['messages']
    response = await llm_with_tools.ainvoke(messages)
    return {"messages": [response]}

def should_continue(state: AgentState):
    if state['messages'][-1].tool_calls: return "tools"
    return END

# ==========================================
# ğŸš€ 4. ä¸»ç¨‹åº (è‡ªåŠ¨å¼¹çª— + æŒä¹…åŒ–è®°å¿†ç‰ˆ)
# ==========================================
async def main():
    global GLOBAL_PAGE
    VISITED_URLS.clear()

    print("\nğŸš€ æ­£åœ¨å¯åŠ¨ Nexus (Auto-Launch Mode)...")
    
    # 1. å®šä¹‰æ•°æ®å­˜å‚¨ç›®å½• (å½“å‰ç›®å½•ä¸‹çš„ browser_data æ–‡ä»¶å¤¹)
    # è¿™å°±æ˜¯æµè§ˆå™¨çš„â€œå¤§è„‘è®°å¿†åŒºâ€ï¼Œå­˜ Cookie å’Œ ç™»å½•çŠ¶æ€
    user_data_dir = os.path.abspath("./nexus_browser_data")
    if not os.path.exists(user_data_dir):
        os.makedirs(user_data_dir)

    async with async_playwright() as p:
        try:
            # === ä½ çš„åŸç”Ÿå¯åŠ¨é…ç½® (ä¿ç•™äº†å»æ¨ªæ¡) ===
            browser_context = await p.chromium.launch_persistent_context(
                user_data_dir=user_data_dir,
                headless=False,
                channel="chrome",
                # å»é™¤ "Chrome æ­£å—åˆ°è‡ªåŠ¨æµ‹è¯•è½¯ä»¶çš„æ§åˆ¶"
                ignore_default_args=["--enable-automation"], 
                args=[
                    "--start-maximized", 
                    "--disable-blink-features=AutomationControlled", # ä¼ªè£…æˆçœŸäºº
                    "--no-sandbox",
                    "--disable-infobars",
                ],
                viewport={"width": 1920, "height": 1080},
            )
            
            # æ³¨å…¥éšèº« JS
            await browser_context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                })
            """)
            
            GLOBAL_PAGE = browser_context.pages[0]
         

            # æ„å»ºå›¾
            workflow = StateGraph(AgentState)
            workflow.add_node("agent", call_deepseek)
            workflow.add_node("tools", tool_node)
            workflow.add_edge(START, "agent")
            workflow.add_conditional_edges("agent", should_continue)
            workflow.add_edge("tools", "agent")
            app = workflow.compile()

            # ä»»åŠ¡
            task = "çš‡å®¤æˆ˜äº‰ç°åœ¨çš„ç»è¥æ€ä¹ˆæ ·å’ŒåŒç±»æ¸¸æˆè¿›è¡Œå¯¹æ¯”"
            
            print(f"\nğŸ¯ ä»»åŠ¡å¯åŠ¨: {task}\n")
            
            async for chunk in app.astream({"messages": [HumanMessage(content=task)]}, stream_mode="values"):
                last_msg = chunk["messages"][-1]
                if last_msg.type == "ai":
                    if last_msg.tool_calls:
                        print(f"ğŸ§  [DeepSeek å†³ç­–]: {last_msg.tool_calls[0]['name']} Args: {last_msg.tool_calls[0]['args']}")
                    else:
                        print(f"ğŸ¤– [DeepSeek æ€»ç»“]:\n{last_msg.content}")
            
            print("\nâœ… ä»»åŠ¡å®Œæˆï¼ä¸ºäº†è®©ä½ çœ‹æ¸…æ¥šï¼Œæµè§ˆå™¨å°†ä¿æŒæ‰“å¼€ 60 ç§’...")
            await asyncio.sleep(60)
            
        except Exception as e:
            print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
            print("ğŸ’¡ å¦‚æœæŠ¥é”™ï¼Œè¯·æ£€æŸ¥ï¼š\n1. ä½ çš„ç”µè„‘è£…äº† Chrome å—ï¼Ÿ\n2. è¯·åŠ¡å¿…ã€å…³é—­æ‰€æœ‰å·²ç»æ‰“å¼€çš„ Chrome çª—å£ã€‘å†è¿è¡Œæ­¤ç¨‹åºï¼")

if __name__ == "__main__":
    asyncio.run(main())